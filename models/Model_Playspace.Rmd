---
title: "Scalar_M1"
author: "BPeloquin"
date: "April 23, 2015"
output: html_document
---

Preliminaries.

```{r}
rm(list=ls())
setwd("~/Desktop/Projects/scalar_implicature/")
source("analysis/useful_dplyr.R")
library(rjson)
```

## Notes
* <none, some, all> condition: the model correctly produces implicature.
* However "all"" condition is predicted to be compabitible with a 4 rating.
* This appears to be driven by several factors
  * 1) High priors over 4
  * 2) Fairly high compabitibiliy with All and four stars from e5

## Basic form of the model

$$p_{L_p} (r \mid u) \propto \frac{p_S(u | r) p_{L_0}(r)}{\sum_{u' \in alts}{p_S(u' \mid r) p_{L_0}(r)}}$$

Read Data ---->
---------

```{r}
priors = read.csv("models/prior.csv")
# Possible transformations --->
priors$prior.p = sqrt(priors$prior.p)/(sum(sqrt(priors$prior.p)))
#priors$prior.p = (1/(-log(priors$prior.p))) / sum((1/(-log(priors$prior.p))))
#priors$prior.p = (log(priors$prior.p + 1)) / sum((log(priors$prior.p + 1)))
speaker = read.csv("models/speaker.csv")
#speaker.alt = read.csv("models/e5a.csv")
listener = read.csv("models/listener.csv")
```

## MODEL IMPLEMENTATION

Key:
* u = utterance [string]
* alts = alternative utterances
* r = rating index [1-5]
* d.info = informativity judgements

```{r}
#cost function in length of chars
# u.cost = function(u) {
#   return(nchar(u))
# }

#speaker likelihood helper 
speaker.lhd = function(d, alpha, cost = 0) {
  exp(alpha*(log(d) - cost)) #Rethink alpha and costs?
}

#speaker likelihood normalized
speaker.prob = function(rating, degree, m, alpha) {
  num = speaker.lhd(m[rating, degree], alpha)
  norm = 0
  for (i in 1:ncol(m)) {
    norm = norm + speaker.lhd(m[rating, i], alpha)
  }
  return(num / norm)
}

#non-normalized posterior
nn.post = function(rating, degree, m, alpha, useprior) {
  
  if (useprior) {
    prior <- priors[rating, "prior.p"]
  } else { #unif prior
    prior = .2 
  }
  speaker.prob(rating, degree, m, alpha) * prior
}

#normalized posterior
norm.post = function(rating, degree, m, alpha, useprior) {
  nn = nn.post(rating, degree, m, alpha, useprior)
  norm = 0
  for (i in 1:5) {
    norm = norm + nn.post(i, degree, m, alpha, useprior)
  }
  return(nn / norm)
}  
```

model wrapper functions:

```{r}
run.rsa <- function(d, alpha = 1, useprior = TRUE, usenone = FALSE) {

  mat <- d %>%
    select(stars, degree, speaker.p) %>%
    spread(degree, speaker.p) %>%
    mutate(hi = hi / sum(hi), 
           low = low / sum(low)) %>%
    select(hi, low)
  
  if (usenone) {
    mat$none <- c(.9, .1, 0, 0, 0)
    mat$neg_valence <- c(.2, .5, .2, .1, 0)
  } 
  
  d$pred <- round(as.numeric(mapply(norm.post, d$stars, d$degree, 
                                    MoreArgs = list(m = mat, 
                                                    alpha = alpha, 
                                                    useprior = useprior))), 
                  digits=4)
  
  return(d)
} 
```


RUN MODEL
--------

Run model on actual data

```{r}
data <- left_join(speaker, listener) %>%
  left_join(priors) %>%
  rowwise %>%
  select(scale, degree, stars, speaker.p, listener.p, prior.p) %>%
  mutate(listener.p = ifelse(is.na(listener.p), 0, listener.p)) %>%
  group_by(scale)
```

## RUN MODEL 

```{r}
# Which alpha has tightest correlation with human judgements
alphas = seq(from=1, to=20)
fit = sapply(alphas, FUN=function(n) {
  md <- data %>%
    do(run.rsa(., alpha = n, useprior = TRUE, usenone = TRUE))
  
  mean((md$pred - md$listener.p)^2)
  #cor(md$pred, md$listener.p)
})
qplot(alphas, fit, main="MSE for alpha values", ylab="MSE")
best.alpha = which(fit == min(fit))
best.alpha

# RUN MODEL
md <- data %>%
  do(run.rsa(., alpha = best.alpha, useprior = TRUE, usenone = TRUE))
```

## DATA / PLOTS ------------>

```{r}
# Facets all scales, Model vs Human judgements
qplot(stars, listener.p, col=degree, 
      data=md, main="Model vs Human judgments",
      ylab="Posterior judgments p(r|u)") + 
  facet_wrap(~scale) + 
  geom_line(aes(y = pred), lty = 4)

ggplot(md, aes(x=listener.p, y=pred)) +
    geom_point(aes(colour = stars)) +
    geom_smooth(method=lm) + ggtitle("Model pred vs Human judgment")
cor(md$pred, md$listener.p)
```


Speaker informativity measures
```{r}
# Scalar judgment scores by rating
qplot(x = stars, y = speaker.judgment, col = degree, ymax = 5,
      geom = "line", stat = "identity", 
      position = "dodge", 
      data = speaker, main= "Scalar + Rating compabililty") + 
  geom_linerange(aes(ymin = speaker.judgment - speaker.cil, 
                     ymax = speaker.judgment + speaker.cih)) + 
  facet_wrap(~scale)

# Scalar compatibility (information ratings)
qplot(x = stars, y = speaker.p, col = degree, ymax = 1,
      geom = c("point", "smooth"), stat = "identity", 
      position = "dodge", 
      data = speaker, main= "Scalar Compaibility distr") + 
  facet_wrap(~scale)
```


Pragmatic Listener Judgments
```{r}
qplot(x=stars, y=listener.p, col=degree, ymax=1,
      geom=c("point", "smooth"), stat = "identity",
      ylab="Compatibility", position="dodge", 
      data=listener, main="Pragmatic listener judgements") + 
  facet_wrap(~scale)
```


Model judgments
```{r}
qplot(x = stars, y = pred, col = degree, ymax = 1, ylab="Posterior judgments",
      geom = c("point", "smooth"), stat = "identity", 
      position = "dodge", 
      data = md, main= "Scalar + Rating compabililty") + 
  facet_wrap(~scale)
```


Priors
```{r}
qplot(c(1:5), priors$prior.p,
      geom="bar", stat = "identity",
      binwidth = 1, main="Priors over ratings")

shapiro.test(priors$prior.p)
ks.test(priors$prior.p, "pnorm", mean=mean(priors$prior.p), sd=sd(priors$prior.p))
```

```{r}
#Some properties of our scales
scales = levels(d$scale)[1:5]
scales.info = sapply(scales, FUN=function(s) {
    curr <- data %>%
      filter(scale == s, degree == "hi") %>%
      select(speaker.p)
    return( c(sd(as.numeric(unlist(curr[,2]))),
              mean(as.numeric(unlist(curr[,2])))))
})
row.names(scales.info) = c("sd", "mean")
scales.info <- t(scales.info)
```
