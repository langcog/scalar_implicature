---
title: "RSA_model2"
author: "BPeloquin"
date: "August 6, 2015"
output: html_document
---

Set-up
------

```{r}
rm(list=ls())

library(ggplot2)
library(knitr)
library(rjson)
library(dplyr)
library(tidyr)

#setwd("~/Desktop/Projects/scalar_implicature/")
#source("analysis/useful_dplyr.R")
```

# RSA functionality

Generic posterior computation
```{r}
# speaker informativity
# ---------------------
speaker.lhd = function(d, alpha, cost = 0) {
  exp(alpha*(log(d) - cost))
}
# speaker likelihood
# ------------------
speaker.prob = function(rating, degree, m, alpha) {
  numerator = speaker.lhd(m[rating, degree], alpha)
  norm = 0
  for (i in 1:ncol(m)) {
    norm = norm + speaker.lhd(m[rating, i], alpha)
  }
  return(numerator / norm)
}
# non-normalized posterior
# -----------------------
nn.post = function(rating, degree, m, alpha, useprior) {
  prior = priors[rating, "prior.p"]
  speaker.prob(rating, degree, m, alpha) * prior
}
# normalized posterior
# --------------------
norm.post = function(rating, degree, m, alpha, useprior) {
  nn = nn.post(rating, degree, m, alpha, useprior)
  norm = 0
  for (i in 1:5) {
    # summation over all scale mates
    norm = norm + nn.post(i, degree, m, alpha, useprior)
  }
  return(nn / norm)
}  
```

# Run functionality
```{r}
# run.partial()
# ------------
# Run RSA with model1 (entailment) and model2 (entailment + generic)
run.partial <- function(d, alpha = 1, useprior = F, usenone = F) {
  mat <- d %>%
    select(stars, degree, speaker.p) %>%
    spread(degree, speaker.p) %>%
    mutate(hi = hi / sum(hi), 
           low = low / sum(low)) %>%
    select(hi, low)
  
  if (usenone) {
    mat$none <- c(1, 0, 0, 0, 0)
  } 
  
  d$pred <- round(as.numeric(mapply(norm.post, d$stars, d$degree, 
                                    MoreArgs = list(m = mat, 
                                                    alpha = alpha, 
                                                    useprior = useprior))), 
                  digits=4)
  
  return(d)
} 

# run.full()
# ------------
# Run RSA with model3 (full) with alternatives
run.full <- function(d, alpha = 1, useprior = F, usenone = F) {
  mat <- d %>%
    select(stars, degree, speaker.p) %>%
    spread(degree, speaker.p) %>%
    mutate(hi1 = hi1 / sum(hi1),
           hi2 = hi2 / sum(hi2),
           low1 = low1 / sum(low1),
           low2 = low2 / sum(low2)) %>%
    select(hi1, hi2, low1, low2)
  
  if (usenone) {
    mat$none <- c(1, 0, 0, 0, 0)
  } 
  
  d$pred <- round(as.numeric(mapply(norm.post, d$stars, d$degree, 
                                    MoreArgs = list(m = mat, 
                                                    alpha = alpha, 
                                                    useprior = useprior))), 
                  digits=4)
  
  return(d)
} 

# tune.alhpa()
# ------------
# d        --> data
# alphas   --> range of alphas to test
# type     --> full or partial model
# useprior --> use uniform prior
# usenone  --> use gener None
tune.alpha = function(d, alphas = seq(from=1, to=10), type="partial", useprior = T, usenone=F) {
  # Tune best alphas
  fit = sapply(alphas, FUN=function(n) {
    if (type == "partial") {
      md <- d %>%
        do(run.partial(., alpha = n, useprior = useprior, usenone = usenone))
    } else {
      md <- d %>%
        do(run.full(., alpha = n, useprior = F, usenone = F))
    }
    # MSE
    return(mean((md$pred - md$listener.p)^2))
  })  
  # get lowest MSE
  best.alpha = which(fit == min(fit))
  return(best.alpha)
}
```

# Model Comparisons

## Data for Entailment models
```{r}
# Save performance output
performance.output = data.frame(model=rep(NA, 6), cor=rep(NA, 6))

speaker = read.csv("~/Desktop/Projects/scalar_implicature/models/model_data/L0_e8.csv")
listener = read.csv("~/Desktop/Projects/scalar_implicature/models/model_data/L1_e6.csv")
# Uniform priors
priors = data.frame(stars = seq(1, 5), prior.p = rep(0.2, 5))
# Combine speaker / listener
data = left_join(speaker, listener) %>%
  left_join(priors) %>%
  rowwise %>%
  select(scale, degree, stars, speaker.p, listener.p, prior.p) %>%
  mutate(listener.p = ifelse(is.na(listener.p), 0, listener.p)) %>%
  group_by(scale)

```

## Data for full model
```{r}
speaker = read.csv("~/Desktop/Projects/scalar_implicature/models/model_data/L0_e10.csv")
listener = read.csv("~/Desktop/Projects/scalar_implicature/models/model_data/L1_e11.csv")
```

## Run comparisons
```{r}
# Model 1 - Entailment, no alpha tuning
# -------------------------------------
m1.noFit = data %>%
  do(run.partial(., alpha = 1, useprior = T, usenone = F))
performance.output[1, ] = c("M1_noFit", round(cor(m1.noFit$listener.p, m1.noFit$pred)^2, 5))

# Model 1 - Entailment, alpha tuning
# ----------------------------------
best.alpha = tune.alpha(data)
m1.fit = data %>%
  do(run.partial(., alpha = best.alpha))
performance.output[2, ] = c("M1_Fit", round(cor(m1.fit$listener.p, m1.fit$pred)^2, 5))

# Model 2 - Entailment, generic "None", no alpha tuning
# -----------------------------------------------------
m2.noFit = data %>%
  do(run.partial(., alpha = 1, usenone = T))
performance.output[3, ] = c("M2_noFit", round(cor(m2.noFit$listener.p, m2.noFit$pred)^2, 5))

# Model 2 - Entailment, generic "None", alpha tuning
# ----------------------------------
best.alpha = tune.alpha(data, usenone = T)
m2.fit = data %>%
  do(run.partial(., alpha = best.alpha, usenone = T))
performance.output[4, ] = c("M2_Fit", round(cor(m2.fit$listener.p, m2.fit$pred)^2, 5))
```



Visualize
---------
```{r}
qplot(stars, listener.p, col=degree, 
      data=md,
      main=paste("Model vs Human judgments\nSemantics measured empirically\nalpha=",
                 alpha),
      ylab="Posterior p(rating | word)") + 
  facet_wrap(~scale) + 
  geom_line(aes(y = pred), lty = 4)

ggplot(md, aes(x=pred, y=listener.p)) +
    geom_point(aes(colour = stars)) +
    geom_smooth(method=lm) +
  ggtitle("Model performance: Baseline") +
  labs(x = "model prediction", y="human judgments")
cor(md$pred, md$listener.p)^2
cor.test(md$pred, md$listener.p)
# scalar level cor
specific.cor = function(scalar) {
  return (cor(md[which(md$scale==scalar), ]$pred,
              md[which(md$scale==scalar), ]$listener.p))
}
qplot(unique(md$scale), y = sapply(unique(md$scale), specific.cor),
    aes(group=1), geom="bar", stat="identity")
```

Tuning
-------
```{r}
# alpha
tune.alpha = function(d, alphas = seq(from=1, to=10)) {
  fit = sapply(alphas, FUN=function(n) {
    md <- d %>%
      do(run.rsa(., alpha = n, useprior = F, usenone = F))
    return(mean((md$pred - md$listener.p)^2))
    #return(cor(md$pred, md$listener.p))
  })  
  best.alpha = which(fit == min(fit))
  return(best.alpha)
}




alphas = seq(from=1, to=10)
fit = sapply(alphas, FUN=function(n) {
  md <- data %>%
    do(run.rsa(., alpha = n, useprior = F, usenone = F))
  return(mean((md$pred - md$listener.p)^2))
  #return(cor(md$pred, md$listener.p))
})
qplot(alphas, fit, main="Cor for alpha values", ylab="MSE")
best.alpha = which(fit == min(fit))
best.alpha
```


For Presentation to Symsys290 10.26.15
```{r}
qplot(stars, listener.p, col=degree, 
      data=md[md$scale=="some_all",],
      main=paste("Model vs Human judgments\nalpha=",
                 alpha),
      ylab="Posterior p(m | u)") +
  geom_line(aes(y = pred), lty = 4)
```

