---
title: "data_cleaning"
author: "BPeloquin"
date: "November 1, 2015"
output:
  html_document:
    highlight: pygments
    theme: flatly
    toc: yes
---


Data cleaning code for Literal listener and Pragmatic listener experiments
```{r load_data, results="hide", message=FALSE, warning=FALSE}
rm(list = ls())
setwd("/Users/benpeloquin/Desktop/Projects/scalar_implicature/analysis")
source("useful_dplyr.R")
library(rjson)
library(jsonlite)
library(tidyr)
library(dplyr)
```


# Literal Listener study e8 output

## Read in data
```{r read_data, message=FALSE, warning=FALSE}
# Grab raw data from .json
# ------------------------
results_path = "../production-results/e8/"
files = dir(results_path, pattern = "*.json")
d.raw = data.frame()

for (f in files) {
  jf = paste(results_path, f, sep="")
  jd = fromJSON(paste(readLines(jf), collapse=""))
  id = data.frame(workerid = jd$WorkerId,
                   scale = jd$answers$data$scale,
                   degree = jd$answers$data$degree,
                   stars = jd$answers$data$manipulation_level,
                   judgment = as.numeric(jd$answers$data$judgment),
                   language = jd$answers$data$language)
  d.raw = bind_rows(d.raw, id)
}

str(d.raw)
head(d.raw)
```

## Compliance checks

I'm holding off on compliance for e8. We made it a bit easier in e10 (both were agreement) and I think we're missing a large portion of the sample unncessarily.

1. training1:high  -> presented 5 stars asked if the person thought the food deserved a `high` rating

2. training:low    -> presented 4 stars, asked if the person thought the food deserved a `low` rating
```{r}
# Sample size pre compliance check
n.pre.compliance = length(unique(d.raw$workerid))
# Check for compliance
compliant <- d.raw %>% 
  filter(grepl("training1", scale)) %>%
  group_by(workerid) %>%
  summarise(compliant = judgment[scale == "training1" & degree == "hi"] == 1 & 
              judgment[scale == "training1" & degree == "low"] == 0)

# Sample size post compliance check
n.post.compliance = sum(compliant$compliant)

# If set to TRUE then enforce compliance for e8 (n reduced to 16)
if (FALSE) { # Enforce compliance check for training 1
  d <- d.raw %>% 
  left_join(compliant) %>%
  filter(grepl(pattern = "english", 
               language, ignore.case = TRUE), 
         scale != "training1", 
         compliant == TRUE)
} else { # Only enforce language check
  d <- d.raw %>% 
  left_join(compliant) %>%
  filter(grepl(pattern = "english", 
               language, ignore.case = TRUE), 
         scale != "training1")
}

# Current sample
n.post.compliance = length(unique(d$workerid)); n.post.compliance
```

## Cleaning / formatting - output
```{r}
# Preliminary data cleaning
# -------------------------
ms = d %>%
  mutate(stars = as.numeric(as.character(stars))/20) %>%
  group_by(scale, degree, stars) %>%
  summarise(cil = ci.low(judgment), 
            cih = ci.high(judgment), 
            cnt.judgment = sum(judgment),
            speaker.p = mean(judgment)) 

str(ms)
head(ms)
# Output to CSV
# --------------
# write.csv(ms, "../models/L0_e8.csv", row.names=FALSE)
```

# Literal Listener study e10 output

## Read in data
```{r read_data2, message=FALSE, warning=FALSE}
results_path = "../production-results/e10/"
files <- dir(results_path, pattern = "*.json")
d.raw <- data.frame()

for (f in files) {
  jf = paste(results_path,f,sep="")
  jd = fromJSON(paste(readLines(jf), collapse=""))
  id = data.frame(workerid = jd$WorkerId, 
                   scale = jd$answers$data$scale,
                   degree = jd$answers$data$degree,
                   stars = jd$answers$data$manipulation_level,
                   judgment = as.numeric(jd$answers$data$judgment),
                   language = jd$answers$data$language)
  d.raw = bind_rows(d.raw, id)
}

str(d.raw)
head(d.raw)
```

## Compliance checks

Enforce compliance in e10. This check seemed more reasonable: 

1. training1:high2  -> presented 5 stars asked if the person thought the food deserved a `high(est)` rating

2. training:low1    -> presented 1 star, asked if the person thought the food deserved a `low(est)` rating
```{r}
# Sample size pre compliance check
n.pre.compliance = length(unique(d.raw$workerid)); n.pre.compliance

compliant <- d.raw %>% 
  filter(grepl("training", scale)) %>%
  group_by(workerid) %>%
  summarise(compliant = (judgment[scale == "training1" & degree == "hi2"] == 1) && 
              (judgment[scale == "training1" & degree == "low1"] == 1))

num_uncompliant = sum(compliant$compliant == FALSE); num_uncompliant

d <- d.raw %>% 
  left_join(compliant) %>%
  filter(grepl(pattern = "english", 
               language, ignore.case = TRUE), 
         scale != "training1",  
         compliant == TRUE)

# Sample size post compliance check
n.post.compliance = sum(compliant$compliant); n.post.compliance
```

## Cleaning / formatting - output
```{r}
# Preliminary data cleaning
# -------------------------
ms = d %>%
  mutate(stars = as.numeric(as.character(stars))/20) %>%
  group_by(scale, degree, stars) %>%
  summarise(cil = ci.low(judgment), 
            cih = ci.high(judgment), 
            cnt.judgment = sum(judgment),
            speaker.p = mean(judgment)) 
str(ms)
head(ms)
# Output to CSV
# --------------
# write.csv(ms, "../models/L0_e10.csv", row.names=FALSE)
```


# Pragmatic Listener study e6 output

## Read in data
```{r read_data3, message=FALSE, warning=FALSE}
results_path = "../production-results/e6/"
files = dir(results_path, pattern = "*.json")
d.raw = data.frame()

for (f in files) {
  jf = paste(results_path,f,sep="")
  jd = fromJSON(paste(readLines(jf), collapse=""))
  id = data.frame(workerid = jd$WorkerId, 
                   scale = jd$answer$scale,
                   degree = jd$answer$degree,
                   stars = as.numeric(jd$answer$judgment),
                   language = jd$answer$language)
  d.raw = bind_rows(d.raw, id)
}
```

## Compliance checks

Enforce compliance in e6.

1. training1:high  -> 

2. training:low    -> 
```{r}
# Sample size pre compliance check
n.pre.compliance = length(unique(d.raw$workerid)); n.pre.compliance

compliant = d.raw %>% 
  filter(grepl("training", scale)) %>%
  group_by(workerid) %>%
  summarise(compliant = stars[scale == "training1" & degree == "hi"] > 3 & 
              stars[scale == "training1" & degree == "low"] < 3)
  
d = d.raw %>% 
  left_join(compliant) %>%
  filter(grepl(pattern = "english", 
               language, ignore.case = TRUE), 
         scale != "training1", 
         compliant == TRUE)

# Sample size post compliance check
n.post.compliance = length(unique(d$workerid)); n.post.compliance
```

## Cleaning / formatting - output
```{r}
# Preliminary data cleaning
# -------------------------
ms <- d %>%
  group_by(degree, scale) %>%
  mutate(n = n()) %>%
  group_by(degree, scale, stars) %>%
  summarise(listener.p = n() / n[1])
str(ms)
head(ms)

# Output to CSV
# --------------
# write.csv(ms, "../models/model_data/L1_e6.csv", row.names=FALSE)
```

# Pragmatic Listener study e11 output

## Read in data
```{r read_data4, message=FALSE, warning=FALSE}
results_path = "../production-results/e11/"
files = dir(results_path, pattern = "*.json")
d.raw = data.frame()

for (f in files) {
  jf = paste(results_path,f,sep="")
  jd = fromJSON(paste(readLines(jf), collapse=""))
  id = data.frame(workerid = jd$WorkerId, 
                   scale = jd$answer$data$scale,
                   degree = jd$answer$data$degree,
                   stars = as.numeric(jd$answer$data$judgment),
                   language = jd$answer$data$language)
  d.raw = bind_rows(d.raw, id)
}
```

## Compliance checks

Enforce compliance in e11.

1. training1:high  -> present "Someone said the food derved a `high` rating". Respondent must choose > 3 stars

2. training:low    -> present "Someone said the food deserved a `low` rating". Respondnet must choose < 3 stars
```{r}
# Sample size pre compliance check
n.pre.compliance = length(unique(d.raw$workerid)); n.pre.compliance

compliant <- d.raw %>% 
   filter(grepl("training", scale)) %>%
   group_by(workerid) %>%
   summarise(compliant = stars[scale == "training1" & degree == "hi2"] > 3 & 
               stars[scale == "training1" & degree == "low1"] < 3)

d <- d.raw %>% 
  left_join(compliant) %>%
  filter(grepl(pattern = "english", 
               language, ignore.case = TRUE), 
         scale != "training1", 
         compliant == TRUE)

# Sample size post compliance check
n.post.compliance = length(unique(d$workerid)); n.post.compliance
```

## Cleaning / formatting - output
```{r}
# Preliminary data cleaning
# -------------------------
ms <- d %>%
  group_by(degree, scale) %>%
  mutate(n = n()) %>%
  group_by(degree, scale, stars) %>%
  summarise(listener.p = n() / n[1],
            total = sum(stars == stars))

# Output to CSV
# --------------
#write.csv(ms, "../models/model_data/L1_e11.csv", row.names=FALSE)
```

```{r}
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```

# Empirically derived alternatives
```{r}
# Code from e9_altsAnalysis.Rmd
d1 = fromJSON("edited_alts.json", simplifyDataFrame=T)
d1 = as.data.frame(d1, stringsAsFactors = FALSE)

d <- d1 %>% 
  gather(base, alt, 
         palatable, liked, good, loved, some, all, 
         delicious, excellent, memorable, unforgettable) %>%
  mutate(base = as.character(base)) %>%
  rowwise %>%
  mutate(scale = ifelse(base == "some" | base == "all", "some_all", 
                        ifelse(base == "palatable" | base == "delicious", "palatable_delicious",
                               ifelse(base == "liked" | base == "loved", "liked_loved",
                                      ifelse(base == "good" | base == "excellent", 
                                             "good_excellent", "memorable_unforgettable"))))) %>%
  group_by(scale, alt) %>%
  summarise(n = n())

# Plot findings of salient alternatives for each scale
# -------------------------------------------------------
scales = unique(d$scale)
p1 = ggplot(data=d[d$scale==scales[1],], aes(x=reorder(alt, -n), y=n)) +
  geom_bar(stat="identity") + ylim(0, 50) +
  ggtitle(paste("Salient alternatives for ", scales[1])) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
p2 = ggplot(data=d[d$scale==scales[2],], aes(x=reorder(alt, -n), y=n)) +
  geom_bar(stat="identity") +
  ggtitle(paste("Salient alternatives for ", scales[2])) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
p3 = ggplot(data=d[d$scale==scales[3],], aes(x=reorder(alt, -n), y=n)) +
  geom_bar(stat="identity") +
  ggtitle(paste("Salient alternatives for ", scales[3])) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
p4 = ggplot(data=d[d$scale==scales[4],], aes(x=reorder(alt, -n), y=n)) +
  geom_bar(stat="identity") +
  ggtitle(paste("Salient alternatives for ", scales[4])) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
p5 = ggplot(data=d[d$scale==scales[5],], aes(x=reorder(alt, -n), y=n)) +
  geom_bar(stat="identity") +
  ggtitle(paste("Salient alternatives for ", scales[5])) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
#multiplot(p1, p2, p3, p4, p5, cols=1)
```

