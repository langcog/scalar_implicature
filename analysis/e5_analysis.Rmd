PSYCH 130 - EXPERIMENT 4 ANALYSIS
=================================

Preliminaries.

```{r}

rm(list=ls())
#setwd("~/Desktop/Projects/scalar_implicature/")
source("analysis/useful_dplyr.R")
library("rjson")
```

Read in files and consolidate to the same directory. 

```{r}
files <- dir("production-results/e5/", pattern = "*.json")
d.raw <- data.frame()

for (f in files) {
  jf <- paste("production-results/e5/",f,sep="")
  jd <- fromJSON(paste(readLines(jf), collapse=""))
  id <- data.frame(workerid = jd$WorkerId, 
                   scale = jd$answer$scale,
                   degree = jd$answer$degree,
                   stars = jd$answer$manipulation_level,
                   judgment = as.numeric(jd$answer$judgment),
                   language = jd$answer$language)
  d.raw <- bind_rows(d.raw, id)
}

# Number of participants
length(unique(d.raw$workerid))
```

Holding off on exclusions - everyone put English, and training 2 was confusing. 

```{r}
# compliant <- d.raw %>% 
#   filter(grepl("training", scale)) %>%
#   group_by(workerid) %>%
#   summarise(compliant = judgment[scale == "training1" & degree == "hi"] > 3 & 
#               judgment[scale == "training1" & degree == "low"] < 3)
#   
# d <- d.raw %>% 
#   left_join(compliant) %>%
#   filter(grepl(pattern = "english", 
#                language, ignore.case = TRUE), 
#          domain != "training1", 
#          domain != "training2", 
#          compliant == TRUE)
d <- d.raw %>% filter(scale != "training1")
```

Main Analysis
-------------

First look at means broken down by epistemic condition.

```{r}
n = length(unique(d$workerid))

ms <- d %>%
  mutate(stars = as.numeric(as.character(stars))/20) %>%
  group_by(scale, degree, stars) %>%
  summarise(cil = ci.low(judgment), 
            cih = ci.high(judgment), 
            judgment = mean(judgment), 
            p = (judgment - 1)/4)
write.csv(ms, "models/e5.csv", row.names=FALSE)

#### Different take on speaker.p ###
ma <- d %>%
  mutate(stars = as.numeric(as.character(stars))/20) %>%
  group_by(scale, degree, stars) %>%
  summarise(speaker.p = sum( ifelse( (judgment >= 4), 1, 0)))
  #summarise(speaker.p = sum( ifelse( (judgment == 5), stars, 0)))
write.csv(ma, "models/e5a.csv", row.names=FALSE)

table(ma$stars, ma$judgment, ma$degree) / sum(table(ma$stars, ma$judgment))
mn <- filter(ma, scale == "good_excellent", degree=="hi")
nt = table(mn$star, mn$judgment)
nt = nt / sum(nt)

mz <- filter(mz, scale == "good_excellent", degree=="low")
nz = table(mz$star, mz$judgment)

t = nz - nt

t = matrix(table(d$judgment, d$degree), ncol=2, nrow = 5)
p = t[,1] - t[,2]
qplot(c(1, 2, 3, 4, 5), ma$speaker.p)

#Original lexical semantics plot
pdf("plots/e5.pdf", width=8, height = 5)
qplot(x = stars, y = judgment, col = degree,
      geom = "line", stat = "identity", 
      position = "dodge", 
      data = ms) + 
  geom_linerange(aes(ymin = judgment - cil, 
                     ymax = judgment + cih)) + 
  facet_wrap(~scale)
dev.off()

#New lexical semantics plot
qplot(x = stars, y = speaker.p, col = degree,
      geom = "line", stat = "identity", 
      position = "dodge", 
      data = ma) + facet_wrap(~scale)
```

barplot

```{r}
qplot(stars, judgment, facets = degree ~ scale, 
      geom="bar", stat = "identity",
      binwidth = 1, data=ms)

qplot(stars, p, facets = degree ~ scale, 
      geom="bar", stat = "identity",
      binwidth = 1, data=ma)
```

difference scores

```{r}
ms.delta <- ms %>% 
  select(-cil, -cih) %>%
  spread(degree, judgment) %>%
  mutate(delta = ifelse(scale != "liked_loved", hi - low, low - hi))

pdf("plots/e5_delta.pdf", width = 8, height = 3)
qplot(stars, delta, facets = . ~ scale, geom = "line",
      data = ms.delta) + 
  geom_hline(yintercept = 0, lty=2)
dev.off()
```

# Histograms of agreement bins
```{r}
raw.scales <- d %>%
  mutate(stars = as.numeric(as.character(stars))/20) %>%
  group_by(scale, degree, stars)

raw.scales = raw.scales[
  order(raw.scales[,2], raw.scales[,3], raw.scales[,4]),]
raw.scales %>% gather()

barplot(raw.scales[which(
  raw.scales[,"scale"] == "good_excellent"
  & raw.scales[,"degree"] == "low"
  & raw.scales[,"stars"] == 1), ]$judgment)


?gather
library(dplyr)
# From http://stackoverflow.com/questions/1181060
stocks <- data.frame(
  time = as.Date('2009-01-01') + 0:9,
  X = rnorm(10, 0, 1),
  Y = rnorm(10, 0, 2),
  Z = rnorm(10, 0, 4)
)
?spread
gather(stocks, stock, price, -time)
stocksm <- stocks %>% gather(stock, price, -time)
stocksm %>% spread(stock, price)

# for reference -------->
ms <- d %>%
  mutate(stars = as.numeric(as.character(stars))/20) %>%
  group_by(scale, degree, stars) %>%
  summarise(cil = ci.low(judgment), 
            cih = ci.high(judgment), 
            judgment = mean(judgment), 
            p = (judgment - 1)/4)
# for reference -------->
```

# Gaussian Analysis 7-21-15
```{r}
# Just having a look using hard coded mean and var from e5a data
# Note: e5a data looks at counts of likert ratings over 4 on aggreableness
all.x = seq(1, 5, length=100)
all.y = dnorm(x, mean=4.537037037, sd=sqrt(0.285665295))  
plot(all.x,all.y, type="l", lwd=1, ylim = c(0, 1), col="blue")

some.x = seq(1, 5, length=100)
some.y = dnorm(x, mean=4.020522388, sd=sqrt(0.786892264))
plot(some.x,some.y, type="l", lwd=1)

lines(some.x, some.y, col="red")
```
